{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef13e304",
   "metadata": {},
   "source": [
    "#### Part 3 - RAG Evaluation Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34dadc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the evaluation data (same as lecture)\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Raw Q&A doc\n",
    "url_prefix = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-evaluation/'\n",
    "docs_url = url_prefix + 'search_evaluation/documents-with-ids.json'\n",
    "documents = requests.get(docs_url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84337d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth doc\n",
    "# Generated by LLM \n",
    "ground_truth_url = url_prefix + 'search_evaluation/ground-truth-data.csv'\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0be5682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'When does the course begin?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'document': 'c02e79ef'},\n",
       " {'question': 'How can I get the course schedule?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'document': 'c02e79ef'},\n",
       " {'question': 'What is the link for course registration?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'document': 'c02e79ef'},\n",
       " {'question': 'How can I receive course announcements?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'document': 'c02e79ef'},\n",
       " {'question': 'Where do I join the Slack channel?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'document': 'c02e79ef'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1747977d",
   "metadata": {},
   "source": [
    "### RAG Evaluation Methods:\n",
    "1. Offline Method:\n",
    "- Before Implementation of the System \n",
    "- Part 1: Retrival Evaluation: Hit Rate (Recall), Mean Recripical Rank (MRR) \n",
    "- Part 2: LLM Answer Evaluation: Cosine Similarity, LLM as Judge  \n",
    "\n",
    "- Link to full retrival evaluation metrics: https://github.com/DataTalksClub/llm-zoomcamp/blob/main/03-evaluation/search_evaluation/evaluation-metrics.md\n",
    "\n",
    "2. Online Method:\n",
    "- A/B Testing\n",
    "- User Feedback\n",
    "- Real time usage data evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba800de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 2. Evaluation on Retrival System\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1) Recall \n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "# 2) Mean Recripical Ranking (MRR)\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "\n",
    "# Combined Evaluation Function \n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results] # List of whether the retrived doc is the truth doc for each testing query\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942e541e",
   "metadata": {},
   "source": [
    "##### Q1: Retrival Evaluation: MinSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b5f301d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x739034996c30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Q1. Minsearch text\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "import minsearch\n",
    "\n",
    "import io\n",
    "import requests\n",
    "import json \n",
    "\n",
    "\n",
    "# Index the doc\n",
    "index = minsearch.Index(text_fields=['question','text','section'],\n",
    "                keyword_fields=['course','id'])\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0e0bfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': 'c02e79ef'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06ab2209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'When does the course begin?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'document': 'c02e79ef'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65b22b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the retrival and evaluation \n",
    "\n",
    "# Retrive the most relavent doc for the query \n",
    "def search(query, index, course):\n",
    "\n",
    "    boost = {'question': 1.5, 'section': 0.1}  # Specify the relative importance of the search on topics\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict = {'course':course},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    # Put all the retrived document text into a signle content\n",
    "    #context = \"\"\n",
    "    #for ans in results:\n",
    "    #    context += ans['text'] + \"\\n\"\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93494527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'c02e79ef'},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'a482086d'},\n",
       " {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '7842b56a'},\n",
       " {'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What are the prerequisites for this course?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '1f6520ca'},\n",
       " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What can I do before the course starts?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '63394d91'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = search(query = 'When does the course begin?', index = index, course = 'data-engineering-zoomcamp')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c211fa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4627 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4627/4627 [00:22<00:00, 207.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Result Evaluation - Hit Rate (Recall)\n",
    "relevance_total = []\n",
    "\n",
    "for q in tqdm(ground_truth):\n",
    "\n",
    "    doc_id = q['document']\n",
    "    results = search(query=q['question'], index = index, course=q['course'])\n",
    "    relevance = [d['id'] == doc_id for d in results] # if the retrived doc is the truth doc \n",
    "    relevance_total.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee99bb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.848714069591528\n"
     ]
    }
   ],
   "source": [
    "# Hit Rate\n",
    "hit_rate = hit_rate(relevance_total)\n",
    "print(hit_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6212055",
   "metadata": {},
   "source": [
    "##### Q2: Test the performance using Vector Search in MinSearch\n",
    "TF-IDF and Singular Value Decomposition to create embeddings from texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ee1fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the performance using Vector Search in MinSearch\n",
    "from minsearch import VectorSearch\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca7ac266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for the \"question\" field:\n",
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question']\n",
    "    texts.append(t)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "X = pipeline.fit_transform(texts)\n",
    "\n",
    "# Embed the question and answer text \n",
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "vindex.fit(X, documents)\n",
    "\n",
    "\n",
    "def minsearch_vector_search(vector, course):\n",
    "    return vindex.search(\n",
    "        vector,\n",
    "        filter_dict={'course': course},\n",
    "        num_results=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47e3aeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4627/4627 [00:03<00:00, 1233.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert the Questions in the Ground Truth data into vectors and perform the evaluation\n",
    "q = [q['question'] for q in ground_truth]\n",
    "q_vectors = pipeline.fit_transform(q)\n",
    "\n",
    "relevance_total = []\n",
    "\n",
    "for qs in tqdm(range(len(q_vectors))):\n",
    "\n",
    "    doc_id = ground_truth[qs]['document']\n",
    "    q_vector = q_vectors[qs]\n",
    "\n",
    "    results = minsearch_vector_search(vector=q_vector, course = 'data-engineering-zoomcamp')\n",
    "    relevance = [d['id'] == doc_id for d in results] # if the retrived doc is the truth doc \n",
    "    relevance_total.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "100a1435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Error: Failed to clone repository.\\ngit clone git@github.com:DataTalksClub/data-engineering-zoomcamp.git /usr/src/develop/…\\nCloning into '/usr/src/develop/...\\nWarning: Permanently added 'github.com,140.82.114.4' (ECDSA) to the list of known hosts.\\ngit@github.com: Permission denied (publickey).\\nfatal: Could not read from remote repository.\\nIssue: You don’t have permissions to write to DataTalksClub/data-engineering-zoomcamp.git\\nSolution 1: Clone the repository and use this forked repo, which contains your github username. Then, proceed to specify the path, as in:\\n[your github username]/data-engineering-zoomcamp.git\\nSolution 2: create a fresh repo for dbt-lessons. We’d need to do branching and PRs in this lesson, so it might be a good idea to also not mess up your whole other repo. Then you don’t have to create a subfolder for the dbt project files\\nSolution 3: Use https link\",\n",
       "  'section': 'Module 4: analytics engineering with dbt',\n",
       "  'question': 'Setup - Failed to clone repository.',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '9c85f3aa'},\n",
       " {'text': 'If you encounter data type error on trip_type column, it may due to some nan values that isn’t null in bigquery.\\nSolution: try casting it to FLOAT datatype instead of NUMERIC',\n",
       "  'section': 'Module 4: analytics engineering with dbt',\n",
       "  'question': 'Data Type Error when running fact table',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '46aebc79'},\n",
       " {'text': 'Problem: when injecting data to bigquery, you may face the type error. This is because pandas by default will parse integer columns with missing value as float type.\\nSolution:\\nOne way to solve this problem is to specify/ cast data type Int64 during the data transformation stage.\\nHowever, you may be lazy to type all the int columns. If that is the case, you can simply use convert_dtypes to infer the data type\\n# Make pandas to infer correct data type (as pandas parse int with missing as float)\\ndf.fillna(-999999, inplace=True)\\ndf = df.convert_dtypes()\\ndf = df.replace(-999999, None)',\n",
       "  'section': 'Module 4: analytics engineering with dbt',\n",
       "  'question': 'How to automatically infer the column data type (pandas missing value issues)?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'b087fa95'},\n",
       " {'text': 'Check if you specified if_exists argument correctly when writing data from GCS to BigQuery. When I wrote my automated flow for each month of the years 2019 and 2020 for green and yellow data I had specified if_exists=\"replace\" while I was experimenting with the flow setup. Once you want to run the flow for all months in 2019 and 2020 make sure to set if_exists=\"append\"\\nif_exists=\"replace\" will replace the whole table with only the month data that you are writing into BigQuery in that one iteration -> you end up with only one month in BigQuery (the last one you inserted)\\nif_exists=\"append\" will append the new monthly data -> you end up with data from all months',\n",
       "  'section': 'Module 4: analytics engineering with dbt',\n",
       "  'question': 'Build - Why do my fact_trips only contain one month of data?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'de426d2f'},\n",
       " {'text': \"It's up to you which platform and environment you use for the course.\\nGithub codespaces or GCP VM are just possible options, but you can do the entire course from your laptop.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Environment - Do we really have to use GitHub codespaces? I already have PostgreSQL & Docker installed.',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '251218fc'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minsearch_vector_search(vector=q_vectors[0], course = 'data-engineering-zoomcamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d931898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001300338592320438\n"
     ]
    }
   ],
   "source": [
    "print(mrr(relevance_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801f1e22",
   "metadata": {},
   "source": [
    "#### Q3: Vector search for question and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23abf727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x73900c88ed80>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use both Question and Text \n",
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question'] + ' ' + doc['text']\n",
    "    texts.append(t)\n",
    "\n",
    "X = pipeline.fit_transform(texts)\n",
    "\n",
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "vindex.fit(X, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eeab209c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4627/4627 [00:03<00:00, 1198.87it/s]\n"
     ]
    }
   ],
   "source": [
    "relevance_total = []\n",
    "\n",
    "for q in tqdm(range(len(q_vectors))):\n",
    "\n",
    "    doc_id = ground_truth[q]['document']\n",
    "    q_vector = q_vectors[q]\n",
    "\n",
    "    results = minsearch_vector_search(vector=q_vector, course = 'data-engineering-zoomcamp')\n",
    "    relevance = [d['id'] == doc_id for d in results] # if the retrived doc is the truth doc \n",
    "    relevance_total.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b26d70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
