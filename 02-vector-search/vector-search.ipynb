{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2daada99",
   "metadata": {},
   "source": [
    "#### 1. Build Qdrant Client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dca04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"qdrant-client[fastembed]>=1.14.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b141b7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83870c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<qdrant_client.qdrant_client.QdrantClient object at 0x76e3bdbfa120>\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize the client\n",
    "client = QdrantClient(\"http://localhost:6333\") #connecting to local Qdrant instance\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f307a86",
   "metadata": {},
   "source": [
    "#### 2. Data Collection\n",
    "Collect the FAQ data online for indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea45dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "#documents_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0b7f84",
   "metadata": {},
   "source": [
    "Decide which fields to be used for semantic search, which to be used as metadata for filering.\n",
    "\n",
    "Text including Q&A pairs can be used as Search Content, Course Name and Section Name can be used as Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea3436a",
   "metadata": {},
   "source": [
    "#### 3. Collection Creation and Embedding Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6806ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model\": \"BAAI/bge-small-zh-v1.5\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"Qdrant/bge-small-zh-v1.5\",\n",
      "    \"url\": \"https://storage.googleapis.com/qdrant-fastembed/fast-bge-small-zh-v1.5.tar.gz\",\n",
      "    \"_deprecated_tar_struct\": true\n",
      "  },\n",
      "  \"model_file\": \"model_optimized.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), Chinese, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 0.09,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"Qdrant/clip-ViT-B-32-text\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"Qdrant/clip-ViT-B-32-text\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"model.onnx\",\n",
      "  \"description\": \"Text embeddings, Multimodal (text&image), English, 77 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 0.25,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"jinaai/jina-embeddings-v2-small-en\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"xenova/jina-embeddings-v2-small-en\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"onnx/model.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.\",\n",
      "  \"license\": \"apache-2.0\",\n",
      "  \"size_in_GB\": 0.12,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "import json\n",
    "\n",
    "# For simplicity and memory friendly, use 512 dimension for embedding\n",
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "\n",
    "for model in TextEmbedding.list_supported_models():\n",
    "    if model[\"dim\"] == EMBEDDING_DIMENSIONALITY:\n",
    "        print(json.dumps(model, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf9cdff",
   "metadata": {},
   "source": [
    "Points are the central entity Qdrant works with.\n",
    "A point is a record consisting of an ID, a vector, and an optional payload.\n",
    "\n",
    "A collection is a named set of points (i.e., vectors with optional payloads) that you can search within.\n",
    "Think of it as the container for your vector search solution, a single business problem solved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d77a43",
   "metadata": {},
   "source": [
    "When creating a collection, we need to specify:\n",
    "\n",
    "Name: A unique identifier for the collection.\n",
    "Vector Configuration:\n",
    "Size: The dimensionality of the vectors.\n",
    "Distance Metric: The method used to measure similarity between vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e93609da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the collection name\n",
    "collection_name = \"zoomcamp-rag\"\n",
    "\n",
    "# Create the collection with specified vector parameters\n",
    "if not client.collection_exists(\"zoomcamp-rag\"):\n",
    "    client.create_collection(\n",
    "\n",
    "        collection_name=collection_name,\n",
    "    \n",
    "        vectors_config=models.VectorParams(\n",
    "            size=EMBEDDING_DIMENSIONALITY,  # Dimensionality of the vectors\n",
    "            distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2789d157",
   "metadata": {},
   "source": [
    "#### 4. Create, Embed & Insert Points into the Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42db29f",
   "metadata": {},
   "source": [
    "Points are the core data entities in Qdrant. Each point consists of:\n",
    "\n",
    "- ID. A unique identifier. Qdrant supports both 64-bit unsigned integers and UUIDs.\n",
    "- Vector. The embedding that represents the data point in vector space.\n",
    "- Payload (optional). Additional metadata as key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d86da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Points to be upserted\n",
    "\n",
    "# Define the embedding model\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "\n",
    "points = []\n",
    "id = 0\n",
    "\n",
    "for course in documents_raw:\n",
    "    for doc in course['documents']:\n",
    "\n",
    "        point = models.PointStruct(\n",
    "            id=id,\n",
    "            vector=models.Document(text=doc['text'], model=model_handle), #embed text locally with \"jinaai/jina-embeddings-v2-small-en\" from FastEmbed\n",
    "            payload={\n",
    "                \"text\": doc['text'],\n",
    "                \"section\": doc['section'],\n",
    "                \"course\": course['course']\n",
    "            } #save all needed metadata fields\n",
    "        )\n",
    "        points.append(point)\n",
    "\n",
    "        id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "324bc0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointStruct(id=3, vector=Document(text=\"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\", model='jinaai/jina-embeddings-v2-small-en', options=None), payload={'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\", 'section': 'General course-related questions', 'course': 'data-engineering-zoomcamp'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de9b36",
   "metadata": {},
   "source": [
    "Now we’re going to embed and upload points to our collection.\n",
    "\n",
    "First, FastEmbed will fetch&download the selected model (path defaults to os.path.join(tempfile.gettempdir(), \"fastembed_cache\")), and perform inference directly on your machine.\n",
    "\n",
    "Then, the generated points will be upserted into the collection, and the vector index will be built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "254e539b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00,  5.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embed the text points and upsert into collection for retrival\n",
    "client.upsert(\n",
    "\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8d47b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=2, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the filtering condition \n",
    "client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\" # exact matching on string metadata fields\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff7afbf",
   "metadata": {},
   "source": [
    "As the embeddings are upserted into the collection, the collection is ready for query retrival."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f231c1",
   "metadata": {},
   "source": [
    "#### 5. Running a Similarity Search\n",
    "\n",
    "Retrival Process:\n",
    "1. Qdrant compares the query vector to stored vectors (based on a vector index) using the distance metric defined when creating the collection.\n",
    "\n",
    "The closest matches are returned, ranked by similarity.\n",
    "\n",
    "2. Vector index is built for approximate nearest neighbor (ANN) search, making large-scale vector search feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46a36479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, course_filter, top_n = 1):\n",
    "\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "\n",
    "        query = models.Document( # Embed the query text locally with \"jinaai/jina-embeddings-v2-small-en\"\n",
    "            text=query,\n",
    "            model=model_handle),\n",
    "        \n",
    "        query_filter = models.Filter( # filter by course name\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\",\n",
    "                    match=models.MatchValue(value=course_filter)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit = top_n, # top closest matches\n",
    "        with_payload=True #to get metadata in the results\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d053df4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryResponse(points=[ScoredPoint(id=757, version=0, score=0.832627, payload={'text': 'Answer: All midterms and capstones are meant to be solo projects. [source @Alexey]', 'section': 'Projects (Midterm and Capstone)', 'course': 'machine-learning-zoomcamp'}, vector=None, shard_key=None, order_value=None)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Search example\n",
    "import random\n",
    "\n",
    "# Randomly pick up a course question\n",
    "course = random.choice(documents_raw)\n",
    "course_piece = random.choice(course['documents'])\n",
    "#print(json.dumps(course_piece, indent=2))\n",
    "\n",
    "search_result = search(course_piece['question'])\n",
    "display(search_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a859b01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Are projects solo or collaborative/group work?\n",
      "\n",
      "Top Retrieved Answer:\n",
      "Answer: All midterms and capstones are meant to be solo projects. [source @Alexey]\n",
      "\n",
      "Original Answer:\n",
      "Answer: All midterms and capstones are meant to be solo projects. [source @Alexey]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question:\\n{course_piece['question']}\\n\")\n",
    "print(\"Top Retrieved Answer:\\n{}\\n\".format(search_result.points[0].payload['text']))\n",
    "print(\"Original Answer:\\n{}\".format(course_piece['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31281727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\n",
      "Older news:[source1] [source2]\n"
     ]
    }
   ],
   "source": [
    "print(search(\"What if I submit homeworks late?\").points[0].payload['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eebbe3",
   "metadata": {},
   "source": [
    "score – the cosine similarity between the question and text embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78759b62",
   "metadata": {},
   "source": [
    "#### 6. Integrate Semantic Search into LLM Assistant\n",
    "\n",
    "Switch the search engine into Sementic Search with Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "291e96f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.90.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting docx\n",
      "  Downloading docx-0.2.4.tar.gz (54 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Collecting lxml (from docx)\n",
      "  Downloading lxml-5.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: Pillow>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from docx) (11.2.1)\n",
      "Downloading openai-1.90.0-py3-none-any.whl (734 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m734.6/734.6 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Downloading lxml-5.4.0-cp312-cp312-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: docx\n",
      "  Building wheel for docx (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docx: filename=docx-0.2.4-py3-none-any.whl size=53929 sha256=bf612dc91b2d28e0b2f4764f3816d594dc90b8700a0d7e2ad54b0e192550bae1\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/f3/ba/dd/43ed5f165600f41deddeb1e382c56ffc1067c09ec5bd705f39\n",
      "Successfully built docx\n",
      "Installing collected packages: lxml, jiter, distro, docx, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [openai]2m4/5\u001b[0m [openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed distro-1.9.0 docx-0.2.4 jiter-0.10.0 lxml-5.4.0 openai-1.90.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "792da88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57b1ef3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mos\u001b[49m.environ[\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m<API KEY>\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"<API KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70ed98d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the LLM Assistant Function\n",
    "def response(query, context):\n",
    "\n",
    "    # 1. Make the prompt\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "CONTEXT: {context}f\n",
    "\"\"\".strip()\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "\n",
    "    # 2. Get the answer using LLM\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de1362ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(user_query, course_filter = 'data-engineering-zoomcamp', top_n = 5):\n",
    "\n",
    "    context = search(query = user_query, course_filter = course_filter, top_n = top_n)\n",
    "    answer = response(query = user_query, context = context)\n",
    "    \n",
    "    return answer  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9daf2f",
   "metadata": {},
   "source": [
    "##### Try Sample Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15ac5937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c4df7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The provided CONTEXT does not contain specific information about where to submit your homework. Please refer to your course guidelines or contact your instructor for the correct submission process."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'Where can I submit my homework?'\n",
    "\n",
    "answer = rag(user_query=question, course_filter = \"mlops-zoomcamp\")\n",
    "Markdown(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
